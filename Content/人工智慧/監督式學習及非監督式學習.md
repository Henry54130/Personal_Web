| 比較項目           | **監督學習（Supervised Learning）**     | **非監督學習（Unsupervised Learning）**                                    |
| -------------- | --------------------------------- | ------------------------------------------------------------------- |
| **是否需要標籤資料**   | ✅ 需要（每筆資料都有輸入 x 與標籤 y）            | ❌ 不需要（只有輸入 x，沒有 y）                                                  |
| **目標**         | 學習輸入與標籤之間的關係                      | 發現資料內在結構、模式或關聯性                                                     |
| **常見任務**       | 分類（classification）、回歸（regression） | 分群（clustering）、降維（dimensionality reduction）、異常偵測（anomaly detection） |
| **輸出結果**       | 可預測新資料的標籤或值                       | 產生群組、潛在特徵、關聯規則等                                                     |
| **常見演算法**      | 線性/邏輯回歸、SVM、決策樹、隨機森林、神經網路         | k-means、層次式分群、DBSCAN、PCA、Autoencoder、LDA                            |
| **損失函數（Loss）** | 可定義明確的誤差（如 MSE）                   | 通常無明確損失；以距離或相似性作為依據                                                 |
| **訓練資料需求**     | 必須包含正確標籤                          | 只需大量原始資料                                                            |
| **應用範例**       | 信用卡詐欺偵測、醫療影像分類、房價預測               | 客戶分群、主題分析、資料壓縮、異常行為偵測                                               |
| **優點**         | 預測準確、可量化評估                        | 無需標籤、能發現潛在結構                                                        |
| **缺點**         | 標籤取得昂貴；易過擬合                       | 結果主觀、難以評估正確性                                                        |
| **擴充方向**       | 半監督學習、自監督學習（結合標籤與無標籤）             | 可與監督學習結合，做特徵工程或前置分析                                                 |